{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Data: diabetes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we use this data set from Kaggle which tracks diabetes in Pima Native Americans. We use it to build a predictive model of how likely someone is to get or have diabetes given their age, body mass index, glucose and insulin levels, skin thickness, etc.\n",
    "\n",
    "The code below plugs these features (glucode, BMI, etc.) and labels (the single value yes [1] or no [0]) into a Keras neural network to build a model that with about 80% accuracy can predict whether someone has or will get Type II diabetes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "import pandas as pd\n",
    "from keras.layers import Dense\n",
    "\n",
    "data = pd.read_csv('diabetes.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let’s browse the data, listing maximum and minimum and average values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>3.845052</td>\n",
       "      <td>120.894531</td>\n",
       "      <td>69.105469</td>\n",
       "      <td>20.536458</td>\n",
       "      <td>79.799479</td>\n",
       "      <td>31.992578</td>\n",
       "      <td>0.471876</td>\n",
       "      <td>33.240885</td>\n",
       "      <td>0.348958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>3.369578</td>\n",
       "      <td>31.972618</td>\n",
       "      <td>19.355807</td>\n",
       "      <td>15.952218</td>\n",
       "      <td>115.244002</td>\n",
       "      <td>7.884160</td>\n",
       "      <td>0.331329</td>\n",
       "      <td>11.760232</td>\n",
       "      <td>0.476951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.078000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27.300000</td>\n",
       "      <td>0.243750</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>30.500000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0.372500</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>140.250000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>127.250000</td>\n",
       "      <td>36.600000</td>\n",
       "      <td>0.626250</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>199.000000</td>\n",
       "      <td>122.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>846.000000</td>\n",
       "      <td>67.100000</td>\n",
       "      <td>2.420000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Pregnancies     Glucose  BloodPressure  SkinThickness     Insulin  \\\n",
       "count   768.000000  768.000000     768.000000     768.000000  768.000000   \n",
       "mean      3.845052  120.894531      69.105469      20.536458   79.799479   \n",
       "std       3.369578   31.972618      19.355807      15.952218  115.244002   \n",
       "min       0.000000    0.000000       0.000000       0.000000    0.000000   \n",
       "25%       1.000000   99.000000      62.000000       0.000000    0.000000   \n",
       "50%       3.000000  117.000000      72.000000      23.000000   30.500000   \n",
       "75%       6.000000  140.250000      80.000000      32.000000  127.250000   \n",
       "max      17.000000  199.000000     122.000000      99.000000  846.000000   \n",
       "\n",
       "              BMI  DiabetesPedigreeFunction         Age     Outcome  \n",
       "count  768.000000                768.000000  768.000000  768.000000  \n",
       "mean    31.992578                  0.471876   33.240885    0.348958  \n",
       "std      7.884160                  0.331329   11.760232    0.476951  \n",
       "min      0.000000                  0.078000   21.000000    0.000000  \n",
       "25%     27.300000                  0.243750   24.000000    0.000000  \n",
       "50%     32.000000                  0.372500   29.000000    0.000000  \n",
       "75%     36.600000                  0.626250   41.000000    1.000000  \n",
       "max     67.100000                  2.420000   81.000000    1.000000  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 768 entries, 0 to 767\n",
      "Data columns (total 9 columns):\n",
      "Pregnancies                 768 non-null int64\n",
      "Glucose                     768 non-null int64\n",
      "BloodPressure               768 non-null int64\n",
      "SkinThickness               768 non-null int64\n",
      "Insulin                     768 non-null int64\n",
      "BMI                         768 non-null float64\n",
      "DiabetesPedigreeFunction    768 non-null float64\n",
      "Age                         768 non-null int64\n",
      "Outcome                     768 non-null int64\n",
      "dtypes: float64(2), int64(7)\n",
      "memory usage: 54.1 KB\n"
     ]
    }
   ],
   "source": [
    " data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check correlation with heatmap graph\n",
    "Next, run this code to see any correlation between variables. That is not important for the final model but is useful to gain further insight into the data.\n",
    "\n",
    "Seaborn creates a heatmap-type chart, plotting each value from the dataset against itself and every other value. Then it figures out if these two values are in any way correlated with each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1ad309af2c8>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib as plt\n",
    "corr = data.corr()\n",
    "sns.heatmap(corr, \n",
    "            xticklabels=corr.columns.values,\n",
    "            yticklabels=corr.columns.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Items that are perfectly correlated have correlation value 1. Obviously, every metric is perfectly correlated with itself., illustrated by the tan line going diagonally across the middle of the chart.\n",
    "There’s not a lot of orange squares in the chart. So, you can say that no single value is 80% likely to give you diabetes (outcome). There does not seem to be much correlation between these individual variables. But, we will see that when taken in the aggregate we can predict with almost 75% accuracy who will develop diabetes given all of these factors together.\n",
    "\n",
    "You can check the correlation between two variables in a dataframe like shown below.  There is not much correlation here since 0.28 and 0.54 are far from 1.00."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare the test and training data sets\n",
    "Outcome is the column with the label (0 or 1).\n",
    "The rest of the columns are the features.\n",
    "We use the scikit-learn function train_test_split(X, y, test_size=0.33, random_state=42) to split the data into training and test data sets, given 33% of the records to the test data set.  The training data set is used to train the mode, meaning find the weights and biases.  The test data set is used to check its accuracy.\n",
    "labels is not an array. It is a column in a dataset.  So we use the NumPy np.ravel() function to convert that to an array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "labels=data['Outcome']\n",
    "features = data.iloc[:,0:8]\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X=features\n",
    "\n",
    "y=np.ravel(labels)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we normalize the values, meaning take each x in the training and test data set and \n",
    "calculate the distance from the mean divided by the standard deviation. \n",
    "That put the data on a standard scale, which is a standard practice with machine learning.\n",
    "\n",
    "StandardScaler does this in two steps:  fit() and transform()."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "\n",
    "X_train = scaler.transform(X_train)\n",
    "\n",
    "X_test = scaler.transform(X_test)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Keras sequential model\n",
    "The code below created a Keras sequential model, which means building up the layers in the neural network by adding them one at a time, as opposed to other techniques and neural network types.\n",
    "\n",
    "Activation function\n",
    "Pick an activation function for each layer. It takes that ((w • x) + b) and calculates a probability. Then it sets a threshold to determine whether the neuron ((w • x) + b) should be 1 (true) or (0) negative. (That’s not the same as saying diabetic, 1, or not, 0, as neural networks can handle problems with more than just two discrete outcomes.)\n",
    "\n",
    "For the first two layers we use a relu (rectified linear unit) activation function. That choice means nothing, as you could have picked sigmoid.  reluI is 1 for all positive values and 0 for all negative ones.\n",
    "This is the same as saying f(x) = max (0, x). So f(-1), for example = max(0, -1) = 0. In other words, if our probability function is negative, then pick 0 (false). Otherwise pick 1 (true).\n",
    "\n",
    "The rule as to which activation function to pick is trial and error. Pick different ones and see which produces the most accurate predictions. There are others: Sigmoid, tanh, Softmax, ReLU, and Leaky ReLU. Some are more suitable to multiple rather than binary outputs.\n",
    "\n",
    "Sigmoid uses the logistic function, 1 / (1 + e**z) where  z = f(x) =  ((w • x) + b).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(8, activation='relu', input_shape=(8,)))\n",
    "\n",
    "model.add(Dense(8, activation='relu'))\n",
    "\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some notes on the code:\n",
    "\n",
    "input_shape—we only have to give it the shape (dimensions) of the input on the first layer. It’s (8,) since it’s a vector of 8 features. In other words its 8 x 1.\n",
    "Dense—to apply the activation function over ((w • x) + b). The first argument in the Dense function is the number of hidden units, a parameter that you can adjust to improve the accuracy of the model. Hidden units is, like the number of hidden layers, a complex topic not easy to understand or explain, but it’s one we can safely gloss over.  (The complexity of these two topics is what makes most people say that working with neural networks is art. A mathematician would mock that lack of rigor.)\n",
    "\n",
    "loss—the goal of the neural network is to minimize the loss function, i.e., the difference between predicted and observed values. There are many functions we can use. We pick binary_crossentropy because our label data is binary (1) diabetic and (0) not diabetic.\n",
    "optimizer—we use the optimizer function sgd, Stochastic Gradient Descent. It’s an algorithm designed to minimize the loss function in the quickest way possible. There are others.\n",
    "epoch—means how many times to run the model. Remember that it is an iterative process. You could add additional epochs, but the accuracy might not change much. You just have to try and see.\n",
    "metrics—means what metrics to display as it runs. Accuracy means how accurately the evolving model predicts the outcome.\n",
    "batch size—n means divide the input data into n batches and process each in parallel.\n",
    "fit()—trains the model, meaning calculates the weights, biases, number of layers, etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "514/514 [==============================] - 1s 2ms/step - loss: 1.4498 - accuracy: 0.6420\n",
      "Epoch 2/4\n",
      "514/514 [==============================] - 0s 942us/step - loss: 0.6521 - accuracy: 0.6459\n",
      "Epoch 3/4\n",
      "514/514 [==============================] - 0s 932us/step - loss: 0.6512 - accuracy: 0.6459\n",
      "Epoch 4/4\n",
      "514/514 [==============================] - 0s 939us/step - loss: 0.6510 - accuracy: 0.6459\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1ad31857a48>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='sgd',\n",
    "              metrics=['accuracy'])\n",
    "                   \n",
    "model.fit(X_train, y_train,epochs=4, batch_size=1, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, we talked about the iterative process of solving a neural network for weights and bias.  That’s done with epochs. Here is the output as it runs those. As you can see the accuracy goes up quickly then levels off."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.layers:\n",
    "    weights = layer.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pydot in c:\\users\\amit\\anaconda3\\lib\\site-packages (1.4.1)\n",
      "Requirement already satisfied: pyparsing>=2.1.4 in c:\\users\\amit\\anaconda3\\lib\\site-packages (from pydot) (2.4.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install pydot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also draw a picture of the layers and their shapes. It’s not very useful but nice to see."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you would expect, the shape of the output is 1, as there we have our prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict_classes(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This prints the score, or accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254/254 [==============================] - 0s 518us/step\n",
      "[0.641478711695183, 0.6614173054695129]\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test,verbose=1)\n",
    "\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, our predictive model is 72% accurate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tune Batch Size and Number of Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "def DL_Model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(8, activation='relu', input_shape=(8,)))\n",
    "    model.add(Dense(8, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer= 'adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Amit\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.690661 using {'batch_size': 10, 'epochs': 100}\n",
      "0.607004 (0.040586) with: {'batch_size': 10, 'epochs': 10}\n",
      "0.671206 (0.003298) with: {'batch_size': 10, 'epochs': 50}\n",
      "0.690661 (0.034608) with: {'batch_size': 10, 'epochs': 100}\n",
      "0.593385 (0.016918) with: {'batch_size': 20, 'epochs': 10}\n",
      "0.669261 (0.051961) with: {'batch_size': 20, 'epochs': 50}\n",
      "0.653697 (0.035852) with: {'batch_size': 20, 'epochs': 100}\n",
      "0.552529 (0.053944) with: {'batch_size': 40, 'epochs': 10}\n",
      "0.599222 (0.051499) with: {'batch_size': 40, 'epochs': 50}\n",
      "0.628405 (0.011931) with: {'batch_size': 40, 'epochs': 100}\n",
      "0.515564 (0.121114) with: {'batch_size': 60, 'epochs': 10}\n",
      "0.603113 (0.055104) with: {'batch_size': 60, 'epochs': 50}\n",
      "0.661479 (0.032541) with: {'batch_size': 60, 'epochs': 100}\n",
      "0.529183 (0.054522) with: {'batch_size': 80, 'epochs': 10}\n",
      "0.544747 (0.041930) with: {'batch_size': 80, 'epochs': 50}\n",
      "0.651751 (0.022515) with: {'batch_size': 80, 'epochs': 100}\n",
      "0.589494 (0.026787) with: {'batch_size': 100, 'epochs': 10}\n",
      "0.599222 (0.047818) with: {'batch_size': 100, 'epochs': 50}\n",
      "0.622568 (0.017669) with: {'batch_size': 100, 'epochs': 100}\n"
     ]
    }
   ],
   "source": [
    "model = KerasClassifier(build_fn=DL_Model, verbose=0)\n",
    "batch_size = [10, 20, 40, 60, 80, 100]\n",
    "epochs = [10, 50, 100]\n",
    "param_grid = dict(batch_size=batch_size, epochs=epochs)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7362204724409449"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "y_pred=grid.predict(X_test)\n",
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tune Activation,Neurons and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DL_Model(activation= 'linear', neurons= 5, optimizer='Adam'):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neurons, activation=activation, input_shape=(8,)))\n",
    "    model.add(Dense(neurons, activation=activation))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer= optimizer, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "514/514 [==============================] - 0s 785us/step - loss: 1.4853 - accuracy: 0.5798\n",
      "Epoch 2/15\n",
      "514/514 [==============================] - 0s 248us/step - loss: 0.6721 - accuracy: 0.6459\n",
      "Epoch 3/15\n",
      "514/514 [==============================] - 0s 227us/step - loss: 0.6588 - accuracy: 0.6440\n",
      "Epoch 4/15\n",
      "514/514 [==============================] - 0s 213us/step - loss: 0.6542 - accuracy: 0.6459\n",
      "Epoch 5/15\n",
      "514/514 [==============================] - 0s 249us/step - loss: 0.6466 - accuracy: 0.6440\n",
      "Epoch 6/15\n",
      "514/514 [==============================] - 0s 390us/step - loss: 0.6400 - accuracy: 0.6459\n",
      "Epoch 7/15\n",
      "514/514 [==============================] - 0s 353us/step - loss: 0.6447 - accuracy: 0.6498\n",
      "Epoch 8/15\n",
      "514/514 [==============================] - 0s 237us/step - loss: 0.6387 - accuracy: 0.6459\n",
      "Epoch 9/15\n",
      "514/514 [==============================] - 0s 225us/step - loss: 0.6293 - accuracy: 0.6479\n",
      "Epoch 10/15\n",
      "514/514 [==============================] - 0s 209us/step - loss: 0.6225 - accuracy: 0.6518\n",
      "Epoch 11/15\n",
      "514/514 [==============================] - 0s 201us/step - loss: 0.6338 - accuracy: 0.6459\n",
      "Epoch 12/15\n",
      "514/514 [==============================] - 0s 195us/step - loss: 0.6096 - accuracy: 0.6479\n",
      "Epoch 13/15\n",
      "514/514 [==============================] - 0s 195us/step - loss: 0.6195 - accuracy: 0.6595\n",
      "Epoch 14/15\n",
      "514/514 [==============================] - 0s 191us/step - loss: 0.6282 - accuracy: 0.6576\n",
      "Epoch 15/15\n",
      "514/514 [==============================] - 0s 188us/step - loss: 0.6139 - accuracy: 0.6654\n",
      "Max Accuracy Registred: 0.679 using {'activation': 'relu', 'neurons': 15, 'optimizer': 'SGD'}\n"
     ]
    }
   ],
   "source": [
    "model = KerasClassifier(build_fn=DL_Model, verbose=0)\n",
    "activation = ['softmax', 'relu', 'tanh', 'sigmoid']\n",
    "neurons = [5, 10, 15]\n",
    "optimizer = ['SGD', 'Adam','RMSprop']\n",
    "# weight_constraint = [1, 2, 3]\n",
    "# dropout_rate = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5]\n",
    "param_grid = dict(activation = activation, neurons = neurons, optimizer = optimizer)\n",
    "clf = KerasClassifier(build_fn= DL_Model, epochs=15, batch_size=5, verbose= 1)\n",
    "model = GridSearchCV(estimator= clf, param_grid=param_grid, n_jobs=-1)\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "print(\"Max Accuracy Registred: {} using {}\".format(round(model.best_score_,3), \n",
    "                                                   model.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254/254 [==============================] - 0s 554us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6653543307086615"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "y_pred=model.predict(X_test)\n",
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tune Learning Rate and Momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DL_Model(learn_rate=0.01, momentum=0):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(8, activation='relu', input_shape=(8,)))\n",
    "    model.add(Dense(8, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    optimizer = SGD(lr=learn_rate, momentum=momentum)\n",
    "    model.compile(loss='binary_crossentropy', optimizer= optimizer, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Amit\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.669261 using {'learn_rate': 0.01, 'momentum': 0.0}\n",
      "0.655642 (0.020429) with: {'learn_rate': 0.001, 'momentum': 0.0}\n",
      "0.661479 (0.028479) with: {'learn_rate': 0.001, 'momentum': 0.2}\n",
      "0.663424 (0.034974) with: {'learn_rate': 0.001, 'momentum': 0.4}\n",
      "0.651751 (0.006041) with: {'learn_rate': 0.001, 'momentum': 0.6}\n",
      "0.661479 (0.008760) with: {'learn_rate': 0.001, 'momentum': 0.8}\n",
      "0.651751 (0.028398) with: {'learn_rate': 0.001, 'momentum': 0.9}\n",
      "0.669261 (0.031239) with: {'learn_rate': 0.01, 'momentum': 0.0}\n",
      "0.647860 (0.006367) with: {'learn_rate': 0.01, 'momentum': 0.2}\n",
      "0.649805 (0.007822) with: {'learn_rate': 0.01, 'momentum': 0.4}\n",
      "0.642023 (0.005086) with: {'learn_rate': 0.01, 'momentum': 0.6}\n",
      "0.645914 (0.002419) with: {'learn_rate': 0.01, 'momentum': 0.8}\n",
      "0.645914 (0.002419) with: {'learn_rate': 0.01, 'momentum': 0.9}\n",
      "0.645914 (0.002419) with: {'learn_rate': 0.1, 'momentum': 0.0}\n",
      "0.645914 (0.002419) with: {'learn_rate': 0.1, 'momentum': 0.2}\n",
      "0.645914 (0.002419) with: {'learn_rate': 0.1, 'momentum': 0.4}\n",
      "0.645914 (0.002419) with: {'learn_rate': 0.1, 'momentum': 0.6}\n",
      "0.643969 (0.003947) with: {'learn_rate': 0.1, 'momentum': 0.8}\n",
      "0.643969 (0.003947) with: {'learn_rate': 0.1, 'momentum': 0.9}\n",
      "0.640078 (0.008955) with: {'learn_rate': 0.2, 'momentum': 0.0}\n",
      "0.647860 (0.005092) with: {'learn_rate': 0.2, 'momentum': 0.2}\n",
      "0.643969 (0.003947) with: {'learn_rate': 0.2, 'momentum': 0.4}\n",
      "0.643969 (0.003947) with: {'learn_rate': 0.2, 'momentum': 0.6}\n",
      "0.645914 (0.002419) with: {'learn_rate': 0.2, 'momentum': 0.8}\n",
      "0.548638 (0.137591) with: {'learn_rate': 0.2, 'momentum': 0.9}\n",
      "0.643969 (0.003947) with: {'learn_rate': 0.3, 'momentum': 0.0}\n",
      "0.645914 (0.002419) with: {'learn_rate': 0.3, 'momentum': 0.2}\n",
      "0.645914 (0.002419) with: {'learn_rate': 0.3, 'momentum': 0.4}\n",
      "0.643969 (0.000979) with: {'learn_rate': 0.3, 'momentum': 0.6}\n",
      "0.645914 (0.002419) with: {'learn_rate': 0.3, 'momentum': 0.8}\n",
      "0.643969 (0.003947) with: {'learn_rate': 0.3, 'momentum': 0.9}\n"
     ]
    }
   ],
   "source": [
    "from keras.optimizers import SGD\n",
    "model = KerasClassifier(build_fn=DL_Model, epochs=100, batch_size=10, verbose=0)\n",
    "# define the grid search parameters\n",
    "learn_rate = [0.001, 0.01, 0.1, 0.2, 0.3]\n",
    "momentum = [0.0, 0.2, 0.4, 0.6, 0.8, 0.9]\n",
    "param_grid = dict(learn_rate=learn_rate, momentum=momentum)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6614173228346457"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "y_pred=grid.predict(X_test)\n",
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tune Network Weight Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DL_Model(init_mode='uniform'):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(8, activation='relu', input_shape=(8,),kernel_initializer=init_mode))\n",
    "    model.add(Dense(8, activation='relu',kernel_initializer=init_mode))\n",
    "    model.add(Dense(1, activation='sigmoid',kernel_initializer=init_mode))\n",
    "    model.compile(loss='binary_crossentropy', optimizer= 'adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.702335 using {'init_mode': 'normal'}\n",
      "0.669261 (0.038336) with: {'init_mode': 'uniform'}\n",
      "0.659533 (0.021570) with: {'init_mode': 'lecun_uniform'}\n",
      "0.702335 (0.004840) with: {'init_mode': 'normal'}\n",
      "0.645914 (0.002419) with: {'init_mode': 'zero'}\n",
      "0.677043 (0.011176) with: {'init_mode': 'glorot_normal'}\n",
      "0.696498 (0.028531) with: {'init_mode': 'glorot_uniform'}\n",
      "0.671206 (0.030348) with: {'init_mode': 'he_normal'}\n",
      "0.649805 (0.000963) with: {'init_mode': 'he_uniform'}\n"
     ]
    }
   ],
   "source": [
    "model = KerasClassifier(build_fn=DL_Model, epochs=100, batch_size=10, verbose=0)\n",
    "# define the grid search parameters\n",
    "init_mode = ['uniform', 'lecun_uniform', 'normal', 'zero', 'glorot_normal', 'glorot_uniform', 'he_normal', 'he_uniform']\n",
    "param_grid = dict(init_mode=init_mode)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7598425196850394"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "y_pred=grid.predict(X_test)\n",
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tune Dropout Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DL_Model(dropout_rate=0.0, weight_constraint=0):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(8, activation='relu', input_shape=(8,)))\n",
    "    model.add(Dense(8, activation='relu'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer= 'adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.688716 using {'dropout_rate': 0.3, 'weight_constraint': 2}\n",
      "0.663424 (0.015023) with: {'dropout_rate': 0.0, 'weight_constraint': 1}\n",
      "0.678988 (0.036925) with: {'dropout_rate': 0.0, 'weight_constraint': 2}\n",
      "0.678988 (0.004024) with: {'dropout_rate': 0.0, 'weight_constraint': 3}\n",
      "0.680934 (0.023014) with: {'dropout_rate': 0.0, 'weight_constraint': 4}\n",
      "0.647860 (0.054443) with: {'dropout_rate': 0.0, 'weight_constraint': 5}\n",
      "0.663424 (0.023160) with: {'dropout_rate': 0.1, 'weight_constraint': 1}\n",
      "0.638132 (0.007251) with: {'dropout_rate': 0.1, 'weight_constraint': 2}\n",
      "0.673152 (0.017004) with: {'dropout_rate': 0.1, 'weight_constraint': 3}\n",
      "0.657588 (0.009001) with: {'dropout_rate': 0.1, 'weight_constraint': 4}\n",
      "0.657588 (0.031811) with: {'dropout_rate': 0.1, 'weight_constraint': 5}\n",
      "0.638132 (0.003934) with: {'dropout_rate': 0.2, 'weight_constraint': 1}\n",
      "0.643969 (0.018212) with: {'dropout_rate': 0.2, 'weight_constraint': 2}\n",
      "0.667315 (0.025828) with: {'dropout_rate': 0.2, 'weight_constraint': 3}\n",
      "0.655642 (0.023002) with: {'dropout_rate': 0.2, 'weight_constraint': 4}\n",
      "0.667315 (0.017001) with: {'dropout_rate': 0.2, 'weight_constraint': 5}\n",
      "0.649805 (0.009589) with: {'dropout_rate': 0.3, 'weight_constraint': 1}\n",
      "0.688716 (0.023926) with: {'dropout_rate': 0.3, 'weight_constraint': 2}\n",
      "0.630350 (0.013806) with: {'dropout_rate': 0.3, 'weight_constraint': 3}\n",
      "0.636187 (0.011075) with: {'dropout_rate': 0.3, 'weight_constraint': 4}\n",
      "0.626459 (0.007219) with: {'dropout_rate': 0.3, 'weight_constraint': 5}\n",
      "0.638132 (0.011622) with: {'dropout_rate': 0.4, 'weight_constraint': 1}\n",
      "0.678988 (0.018018) with: {'dropout_rate': 0.4, 'weight_constraint': 2}\n",
      "0.643969 (0.014344) with: {'dropout_rate': 0.4, 'weight_constraint': 3}\n",
      "0.671206 (0.015905) with: {'dropout_rate': 0.4, 'weight_constraint': 4}\n",
      "0.655642 (0.029114) with: {'dropout_rate': 0.4, 'weight_constraint': 5}\n",
      "0.657588 (0.015018) with: {'dropout_rate': 0.5, 'weight_constraint': 1}\n",
      "0.677043 (0.015670) with: {'dropout_rate': 0.5, 'weight_constraint': 2}\n",
      "0.649805 (0.004866) with: {'dropout_rate': 0.5, 'weight_constraint': 3}\n",
      "0.649805 (0.018226) with: {'dropout_rate': 0.5, 'weight_constraint': 4}\n",
      "0.640078 (0.013617) with: {'dropout_rate': 0.5, 'weight_constraint': 5}\n",
      "0.659533 (0.012753) with: {'dropout_rate': 0.6, 'weight_constraint': 1}\n",
      "0.643969 (0.007816) with: {'dropout_rate': 0.6, 'weight_constraint': 2}\n",
      "0.647860 (0.005092) with: {'dropout_rate': 0.6, 'weight_constraint': 3}\n",
      "0.632296 (0.024203) with: {'dropout_rate': 0.6, 'weight_constraint': 4}\n",
      "0.642023 (0.011089) with: {'dropout_rate': 0.6, 'weight_constraint': 5}\n",
      "0.640078 (0.008955) with: {'dropout_rate': 0.7, 'weight_constraint': 1}\n",
      "0.640078 (0.012754) with: {'dropout_rate': 0.7, 'weight_constraint': 2}\n",
      "0.651751 (0.006585) with: {'dropout_rate': 0.7, 'weight_constraint': 3}\n",
      "0.645914 (0.008970) with: {'dropout_rate': 0.7, 'weight_constraint': 4}\n",
      "0.645914 (0.002419) with: {'dropout_rate': 0.7, 'weight_constraint': 5}\n",
      "0.642023 (0.010011) with: {'dropout_rate': 0.8, 'weight_constraint': 1}\n",
      "0.647860 (0.005092) with: {'dropout_rate': 0.8, 'weight_constraint': 2}\n",
      "0.653696 (0.006382) with: {'dropout_rate': 0.8, 'weight_constraint': 3}\n",
      "0.647860 (0.009277) with: {'dropout_rate': 0.8, 'weight_constraint': 4}\n",
      "0.643969 (0.003947) with: {'dropout_rate': 0.8, 'weight_constraint': 5}\n",
      "0.642023 (0.006353) with: {'dropout_rate': 0.9, 'weight_constraint': 1}\n",
      "0.642023 (0.007534) with: {'dropout_rate': 0.9, 'weight_constraint': 2}\n",
      "0.645914 (0.004524) with: {'dropout_rate': 0.9, 'weight_constraint': 3}\n",
      "0.645914 (0.002419) with: {'dropout_rate': 0.9, 'weight_constraint': 4}\n",
      "0.649805 (0.004866) with: {'dropout_rate': 0.9, 'weight_constraint': 5}\n"
     ]
    }
   ],
   "source": [
    "model = KerasClassifier(build_fn=DL_Model, epochs=100, batch_size=10, verbose=0)\n",
    "# define the grid search parameters\n",
    "weight_constraint = [1, 2, 3, 4, 5]\n",
    "dropout_rate = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "param_grid = dict(dropout_rate=dropout_rate, weight_constraint=weight_constraint)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6614173228346457"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "y_pred=grid.predict(X_test)\n",
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
